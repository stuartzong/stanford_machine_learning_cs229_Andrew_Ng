{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### good machine learning repository:\n",
    "https://github.com/susanli2016/Machine-Learning-with-Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some basics\n",
    "this is a good reference: \n",
    "\n",
    "https://www.hackerearth.com/practice/machine-learning/prerequisites-of-machine-learning/bayes-rules-conditional-probability-chain-rule/tutorial/\n",
    "\n",
    "* ### 1. Product rule\n",
    "\n",
    "P(X, Y) = P(X|Y)* P(Y)\n",
    "\n",
    "P(X, Y) is the join probability both X and Y will occur. \n",
    "\n",
    "P(Y) is the probability that Y occurs.\n",
    "\n",
    "P(X|Y) is conditional probability. the probability that X occurs given that Y has already occurred.\n",
    "\n",
    "Product rule states that the probability that both X and Y will occur is the product of the probability that Y occurs and the probability that X occurs given that Y has already occurred.\n",
    "\n",
    "* ### 2. chain rule\n",
    "\n",
    "Generalizing the product rule leads to chain rule. \n",
    "\n",
    "P(A,B) = p(A|B) p(B)\n",
    "\n",
    "We can extend this for three variables:\n",
    "\n",
    "P(A,B,C) = P(A| B,C) P(B,C) = P(A|B,C) P(B|C) P(C)\n",
    "\n",
    "and in general to n variables:\n",
    "\n",
    "P(A1, A2, ..., An) = P(A1| A2, ..., An) P(A2| A3, ..., An) P(An-1|An) P(An)\n",
    "\n",
    "* ### 3. Bayes' theorem\n",
    "\n",
    "Bayes rule lets us to update our belief as a event occurs (e.g. new evidence discovered, new information about the event we are trying to predict). \n",
    "\n",
    "$ P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$\n",
    "\n",
    "It is more intuitive to look at an example. \n",
    "event A: having cancer\n",
    "\n",
    "event B: smoke\n",
    "\n",
    "P(A): probability of a person having cancer. suppose we know cancer occurs in 5% general population. so P(A)=0.05. If we want to predict the chance of a person having cancer, we can just say the probability of this person having 5% wihtout knowing any additional information about this person.\n",
    "\n",
    "P(B): probability of a person who smokes. Suppose we know a little more background about this person that he has been a smoker. We now should be able to update our belief and give more accurate prediction P(A|B) based on this new information based on Bayes rule.\n",
    "\n",
    "P(A|B): probability of the person has cancer given that he is a smoker. This is a conditional probability, also called posterior.\n",
    "\n",
    "P(B|A): probability of being a smoker given that the person has cancer.\n",
    "\n",
    "We are trying to estimate the probability of a person having cancer P(A). Since 5% population has cancer, we can just assume the probability that a person having cancer is 0.05. Research has suggested that smoking links to cancer. And we also know the person is a smoker. So this new knowledge (evidence) should allow us to make a more accurate prediction according to Bayes rule. We now know:\n",
    "P(A) = 0.05: 5% population have cancer.\n",
    "P(B) = 0.1: 10% population are smokers.\n",
    "P(B|A) = 0.2: 20% of people who have cancer are smokers.\n",
    "$P(A|B) = \\frac{P(B|A)*P(A)}{P(B)} = \\frac{0.2 \\times 0.05}{0.1} = 10\\% $ \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we look at maximum likelihood parameter estimation using the naive\n",
    "Bayes assumption. Here, the input features $x_j , j = 1, . . . , n$ to our model are discrete,\n",
    "binary-valued variables, so $x_j ∈ {0, 1}$. We call $x = [x_1 x_2 · · · x_n]^T$\n",
    "to be the input vector.\n",
    "For each training example, our output targets are a single binary-value y ∈ {0, 1}. \n",
    "\n",
    "Our\n",
    "model is then parameterized by \n",
    "\\begin{align*}\n",
    "\\begin{split}\n",
    "ϕ_{j|y=0} &= p(x_j = 1|y = 0), \\\\\n",
    "ϕ_{j|y=1} &= p(x_j = 1|y = 1), and\\\\\n",
    "ϕ_y &= p(y = 1). \n",
    "\\end{split}\n",
    "\\end{align*}\n",
    "\n",
    "We model the joint distribution of (x, y) according to\n",
    "\\begin{align*}\n",
    "\\begin{split}\n",
    "p(y) &= (ϕ_y)^y(1 − ϕ_y)^{1−y}\\\\\n",
    "p(x|y = 0) &= \\prod^n_{j=1}p(x_j|y = 0)\\\\\n",
    "&=\\prod^n_{j=1}(ϕ_{j|y=0})^{x_j}(1 − ϕ_{j|y=0})^{1−x_j}\\\\\n",
    "p(x|y = 1) &= \\prod^n_{j=1}p(x_j |y = 1)\\\\\n",
    "&=\\prod^n_{j=1}(ϕ_{j|y=1})^{x_j}(1 − ϕ_{j|y=1})^{1−x_j}\n",
    "\\end{split}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Find the joint likelihood function $ℓ(φ) = log \\prod^m_{i=1} p(x^{(i)}, y^{(i)}; φ)$ in terms of the model parameters given above. Here, φ represents the entire set of parameters {$ϕ_y, ϕ_{j|y=0}, ϕ_{j|y=1}, j = 1, . . . , n$}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implementation of Naive Bayes algorithm for a text classification problem\n",
    "here we use the 20 newsgroups dataset. The dataset has news documents partitioned to 20 different groups based on topics.\n",
    "\n",
    "http://qwone.com/~jason/20Newsgroups/\n",
    "\n",
    "code is adapted from https://github.com/aishajv/Unfolding-Naive-Bayes-from-Scratch for my learning purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "\n",
    "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med'] \n",
    "train = fetch_20newsgroups(subset = 'train',categories = categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(train.data) \n",
    "train_labels = np.array(train.target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: ani@ms.uky.edu (Aniruddha B. Deglurkar)\\nSubject: help: Splitting a trimming region along a mesh \\nOrganization: University Of Kentucky, Dept. of Math Sciences\\nLines: 28\\n\\n\\n\\n\\tHi,\\n\\n\\tI have a problem, I hope some of the 'gurus' can help me solve.\\n\\n\\tBackground of the problem:\\n\\tI have a rectangular mesh in the uv domain, i.e  the mesh is a \\n\\tmapping of a 3d Bezier patch into 2d. The area in this domain\\n\\twhich is inside a trimming loop had to be rendered. The trimming\\n\\tloop is a set of 2d Bezier curve segments.\\n\\tFor the sake of notation: the mesh is made up of cells.\\n\\n\\tMy problem is this :\\n\\tThe trimming area has to be split up into individual smaller\\n\\tcells bounded by the trimming curve segments. If a cell\\n\\tis wholly inside the area...then it is output as a whole ,\\n\\telse it is trivially rejected. \\n\\n\\tDoes any body know how thiss can be done, or is there any algo. \\n\\tsomewhere for doing this.\\n\\n\\tAny help would be appreciated.\\n\\n\\tThanks, \\n\\tAni.\\n-- \\nTo get irritated is human, to stay cool, divine.\\n\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2257"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2257"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'from s let rug nl m m zwart subject catholic church poland organization faculteit der letteren rijksuniversiteit groningen nl lines hello i m writing a paper on the role of the catholic church in poland after can anyone tell me more about this or fill me in on recent books articles in english german or french most important for me is the role of the church concerning the abortion law religious education at schools birth control and the relation church state government thanx masja m m zwart s let rug nl '"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)\n",
    "len(train_labels)\n",
    "process_text(train_data[3])\n",
    "train_labels[:1]\n",
    "train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Examples</th>\n",
       "      <th>Training Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: sd345@city.ac.uk (Michael Collier)\\nSubject: Converting images to HP LaserJet III?\\nNntp-Posting-Host: hampton\\nOrganization: The City University\\nLines: 14\\n\\nDoes anyone know of a good way (standard PC application/PD utility) to\\nconvert ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: ani@ms.uky.edu (Aniruddha B. Deglurkar)\\nSubject: help: Splitting a trimming region along a mesh \\nOrganization: University Of Kentucky, Dept. of Math Sciences\\nLines: 28\\n\\n\\n\\n\\tHi,\\n\\n\\tI have a problem, I hope some of the 'gurus' can he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: djohnson@cs.ucsd.edu (Darin Johnson)\\nSubject: Re: harrassed at work, could use some prayers\\nOrganization: =CSE Dept., U.C. San Diego\\nLines: 63\\n\\n(Well, I'll email also, but this may apply to other people, so\\nI'll post also.)\\n\\n&gt;I've b...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: s0612596@let.rug.nl (M.M. Zwart)\\nSubject: catholic church poland\\nOrganization: Faculteit der Letteren, Rijksuniversiteit Groningen, NL\\nLines: 10\\n\\nHello,\\n\\nI'm writing a paper on the role of the catholic church in Poland after 1989. \\n...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: stanly@grok11.columbiasc.ncr.com (stanly)\\nSubject: Re: Elder Brother\\nOrganization: NCR Corp., Columbia SC\\nLines: 15\\n\\nIn article &lt;Apr.8.00.57.41.1993.28246@athos.rutgers.edu&gt; REXLEX@fnal.gov writes:\\n&gt;In article &lt;Apr.7.01.56.56.1993.228...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                           Training Examples  \\\n",
       "0  From: sd345@city.ac.uk (Michael Collier)\\nSubject: Converting images to HP LaserJet III?\\nNntp-Posting-Host: hampton\\nOrganization: The City University\\nLines: 14\\n\\nDoes anyone know of a good way (standard PC application/PD utility) to\\nconvert ...   \n",
       "1  From: ani@ms.uky.edu (Aniruddha B. Deglurkar)\\nSubject: help: Splitting a trimming region along a mesh \\nOrganization: University Of Kentucky, Dept. of Math Sciences\\nLines: 28\\n\\n\\n\\n\\tHi,\\n\\n\\tI have a problem, I hope some of the 'gurus' can he...   \n",
       "2  From: djohnson@cs.ucsd.edu (Darin Johnson)\\nSubject: Re: harrassed at work, could use some prayers\\nOrganization: =CSE Dept., U.C. San Diego\\nLines: 63\\n\\n(Well, I'll email also, but this may apply to other people, so\\nI'll post also.)\\n\\n>I've b...   \n",
       "3  From: s0612596@let.rug.nl (M.M. Zwart)\\nSubject: catholic church poland\\nOrganization: Faculteit der Letteren, Rijksuniversiteit Groningen, NL\\nLines: 10\\n\\nHello,\\n\\nI'm writing a paper on the role of the catholic church in Poland after 1989. \\n...   \n",
       "4  From: stanly@grok11.columbiasc.ncr.com (stanly)\\nSubject: Re: Elder Brother\\nOrganization: NCR Corp., Columbia SC\\nLines: 15\\n\\nIn article <Apr.8.00.57.41.1993.28246@athos.rutgers.edu> REXLEX@fnal.gov writes:\\n>In article <Apr.7.01.56.56.1993.228...   \n",
       "\n",
       "  Training Labels  \n",
       "0               1  \n",
       "1               1  \n",
       "2               3  \n",
       "3               3  \n",
       "4               3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth=250\n",
    "pd.DataFrame(data=np.column_stack([train_data,train_labels]),columns=[\"Training Examples\",\"Training Labels\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build the Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.array([defaultdict(int) for index in range(2)])\n",
    "d[0].items()\n",
    "d[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \n",
    "    def __init__(self, classes):        \n",
    "        self.classes = classes  \n",
    "        \n",
    "    def process_text(self, txts):\n",
    "        '''\n",
    "        replace non-alphabets to spaces, replace multiple spaces to single space, convert to lower cases\n",
    "        '''\n",
    "        txts = re.sub('[^a-z\\s]+',' ', txts, flags = re.IGNORECASE) \n",
    "        txts = re.sub('(\\s+)',' ',txts) \n",
    "        txts = txts.lower()  \n",
    "        return txts \n",
    "\n",
    "    def count_words(self, txts, clss):\n",
    "        '''\n",
    "        build bag of words dictionary, bow[clss][word]: word_counts, clss=class\n",
    "        '''   \n",
    "        txts = txts[0] # not sure why txts is a np array\n",
    "        for word in txts.split():       \n",
    "            bows[clss][word] += 1 \n",
    "\n",
    "\n",
    "    def train(self, train_data, train_labels):\n",
    "        '''\n",
    "        build bag of words dictionary with nested keys [clss][word]\n",
    "        '''           \n",
    "        #constructing BoW for each class\n",
    "        for ix, clss in enumerate(self.classes):          \n",
    "            clss_data = train_data[train_labels==clss] \n",
    "            clss_data = pd.DataFrame([self.process_text(txts) for txts in clss_data])\n",
    "            #now costruct BoW of this particular category\n",
    "            np.apply_along_axis(self.count_words, 1, clss_data, ix)\n",
    "        return bows       \n",
    "    \n",
    "\n",
    "    def class_priors(self, train_labels):\n",
    "        class_priors = np.empty(self.classes.shape[0])\n",
    "        for i, clss in enumerate(self.classes):           \n",
    "            #Calculating prior probability p(c) for each class\n",
    "            class_priors[i]=np.sum(train_labels == clss)/float(train_labels.shape[0]) \n",
    "        return class_priors  \n",
    "    \n",
    "\n",
    "    def class_wcounts(self, bows):\n",
    "        class_wcounts = np.empty(self.classes.shape[0])\n",
    "        for i, _ in enumerate(self.classes): \n",
    "            class_wcounts[i] = np.sum(np.array(list(bows[i].values())))+1 \n",
    "        return class_wcounts\n",
    "    \n",
    "\n",
    "    def vocabs(self, bows):    \n",
    "        vocabs = []   \n",
    "        for i, _ in enumerate(self.classes):  \n",
    "            vocabs += bows[i].keys()    \n",
    "        vocabs = np.unique(np.array(vocabs))\n",
    "        return vocabs\n",
    "\n",
    "    def denominator(self, class_wcounts, vocabs):\n",
    "        denoms = np.array([class_wcounts[i] + len(vocabs) + 1 for i, _ in enumerate(self.classes)])                                                                          \n",
    "        return denoms\n",
    "    \n",
    "\n",
    "    def model_params(self, bows, class_priors, denoms):\n",
    "        mps = [(bows[i], class_priors[i], denoms[i]) for i, _ in enumerate(self.classes)]                               \n",
    "        mps = np.array(mps)  \n",
    "        return mps\n",
    "\n",
    "    \n",
    "    def predict(self, txts, mps): \n",
    "        ''' \n",
    "        probability of test example in ALL CLASSES\n",
    "        mps, model params tuble (bows, class_wcounts, class_denominators)\n",
    "        for each word, compute likelihood [ count(w|c)+1 ] / [ count(c) + |V| + 1 ] \n",
    "        get count of this test word in training set for each class  \n",
    "        log to prevent underflow! likelihood are all very small fractions, product to sum.\n",
    "        likelihood estimate of the given test texts against every class \n",
    "        but we need posterior probility\n",
    "        '''                                  \n",
    "        likelihood = np.zeros(self.classes.shape[0])       \n",
    "        for i, _ in enumerate(self.classes):\n",
    "            for word in txts.split():     \n",
    "                wcounts_inmodel = mps[i][0].get(word,0)+1                \n",
    "                class_denom = float(mps[i][2])                              \n",
    "                word_prob = wcounts_inmodel/class_denom                  \n",
    "                likelihood[i] += np.log(word_prob)  \n",
    "        post_prob = np.empty(self.classes.shape[0])\n",
    "        for i, _ in enumerate(self.classes):\n",
    "            post_prob[i] = likelihood[i] + np.log(mps[i][1])\n",
    "        return post_prob\n",
    "    \n",
    "\n",
    "    def test(self, test_set, mps):\n",
    "        '''\n",
    "        Determines probability of each test txts against all classes and predicts the label\n",
    "        against which the class probability is maximum\n",
    "        Returns:\n",
    "        preds of test txtss - A single prediction against every test txts\n",
    "        '''  \n",
    "        preds = [] \n",
    "        for txts in test_set:             \n",
    "            txts = process_text(txts)\n",
    "            #simply get the posterior probability of every txts                                  \n",
    "            post_prob = self.predict(txts, mps) \n",
    "            preds.append(self.classes[np.argmax(post_prob)])\n",
    "        return np.array(preds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21267169, 0.25875055, 0.26318121, 0.26539654])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([171596., 136413., 183395., 226217.])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['a', 'aa', 'aaa', 'aaaa', 'aaai', 'aacc', 'aad', 'aah', 'aalborg',\n",
       "       'aamrl'], dtype='<U78')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([202782., 167599., 214581., 257403.])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.21267168808152415"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "202782.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-50.42755283, -49.4692088 , -50.44068273, -51.1601231 ])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pprint\n",
    "classes = np.unique(train_labels)\n",
    "bows = np.array([defaultdict(lambda:0) for index in range(classes.shape[0])])\n",
    "nb = NaiveBayes(np.unique(train_labels))\n",
    "bows = nb.train(train_data, train_labels)\n",
    "class_priors = nb.class_priors(train_labels)\n",
    "class_priors\n",
    "class_wcounts = nb.class_wcounts(bows)\n",
    "class_wcounts\n",
    "vocabs = nb.vocabs(bows)\n",
    "vocabs[:10]\n",
    "denoms = nb.denominator(class_wcounts, vocabs)\n",
    "denoms\n",
    "mps = nb.model_params(bows, class_priors, denoms)\n",
    "mps[0][1]\n",
    "mps[0][2]\n",
    "nb.predict('saf dlfd 877&&* ff!', mps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Test Examples:  1502\n",
      "Number of Test Labels:  1502\n"
     ]
    }
   ],
   "source": [
    "ngs_test = fetch_20newsgroups(subset='test',categories=categories) \n",
    "test_data = ngs_test.data \n",
    "test_labels = ngs_test.target\n",
    "print (\"Number of Test Examples: \",len(test_data))\n",
    "print (\"Number of Test Labels: \",len(test_labels))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Examples:  1502\n",
      "Test Set Accuracy:  93.87483355525966 %\n"
     ]
    }
   ],
   "source": [
    "class_preds = nb.test(test_data, mps) \n",
    "\n",
    "#check how many predcitions actually match original test labels\n",
    "test_acc = np.sum(class_preds == test_labels)/float(test_labels.shape[0]) \n",
    "\n",
    "print (\"Test Set Examples: \",test_labels.shape[0])\n",
    "print (\"Test Set Accuracy: \",test_acc*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we made it. the Naive Bays model is not that naive considering that it has over 93% test accuracy. Yeah!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to understand python object and self\n",
    "https://micropyramid.com/blog/understand-self-and-__init__-method-in-python-class/\n",
    "\n",
    "* class: a set of things (objects) having some properties in common and are different from others by type, kind, qulity etc. class is the blueprint for individual object with exactly the same behaviours.\n",
    "* object: one of the instances (examples) of the class, which can perform the functionalities defined in the class.\n",
    "* self: represent the instance of the class. by using self, we can access the attributes and methods of the class. \n",
    "* __init__: is the contructor, we call this reserved method to create an object from a class. It allows the class to initialize the attributes of a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area of Rectangle: 19200 cm^2\n",
      "Cost of rectangular field: Rs. 38400000 \n"
     ]
    }
   ],
   "source": [
    "class Rectangle:\n",
    "   def __init__(self, length, breadth, unit_cost=0):\n",
    "       self.length = length\n",
    "       self.breadth = breadth\n",
    "       self.unit_cost = unit_cost\n",
    "   \n",
    "   def get_perimeter(self):\n",
    "       return 2 * (self.length + self.breadth)\n",
    "   \n",
    "   def get_area(self):\n",
    "       return self.length * self.breadth\n",
    "   \n",
    "   def calculate_cost(self):\n",
    "       area = self.get_area()\n",
    "       return area * self.unit_cost\n",
    "# breadth = 120 cm, length = 160 cm, 1 cm^2 = Rs 2000\n",
    "r = Rectangle(160, 120, 2000)\n",
    "print(\"Area of Rectangle: %s cm^2\" % (r.get_area()))\n",
    "print(\"Cost of rectangular field: Rs. %s \" %(r.calculate_cost()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Rectangle(160, 120, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
